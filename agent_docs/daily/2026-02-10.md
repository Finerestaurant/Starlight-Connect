# 2026-02-10: 데이터 수집 전략 변경 및 MusicBrainz 연동 계획 수립

**금일 목표:** 데이터 수집의 메인 소스를 '나무위키 크롤링'에서 'MusicBrainz API'로 전환하고, 이를 위한 새로운 기술 계획을 수립한다.

---

## 데이터 수집 전략: 하이브리드 방식

-   **주요 소스 (Primary Source):** **MusicBrainz API**를 사용하여 아티스트, 앨범, 곡, 관계 등 구조화된 데이터를 안정적으로 수집한다.
-   **보조 소스 (Secondary Source):** MusicBrainz를 통해 수집한 데이터에 Credit 정보(작사/작곡 등)가 누락된 경우, **Genius.com API** 등 다른 보조 API를 호출하여 데이터를 보강한다.

## 변경된 작업 계획: MusicBrainz 연동

1.  **환경 설정:**
    -   `backend/requirements.txt` 파일을 생성하고, MusicBrainz API 라이브러리인 `musicbrainzngs`를 추가한다.

2.  **데이터베이스 모델 수정:**
    -   `backend/app/models.py`의 `Song` 및 `Person` 모델에 있는 `genius_id` 필드를 MusicBrainz ID(문자열 UUID)를 저장할 `mbid: Mapped[str]`로 변경한다. `source_url` 필드는 MusicBrainz 페이지 링크를 저장하는 용도로 계속 활용한다.

3.  **MusicBrainz API 모듈 생성:**
    -   `backend/app/musicbrainz_api.py` 파일을 새로 생성한다.
    -   이 파일은 아티스트 검색, 앨범 정보 및 곡별 관계(작사/작곡 등)를 가져오는 등 MusicBrainz API와의 모든 통신을 담당하는 함수들을 포함하게 된다.

4.  **서비스 계층(`services.py`) 리팩토링:**
    -   `CrawlingService`를 `MusicDataService`로 명칭을 변경한다.
    -   미구현 상태였던 데이터 파싱 로직을, `musicbrainz_api.py`를 호출하여 받은 정형화된 데이터를 우리 시스템의 스키마에 맞게 변환하는 로직으로 구체화한다.

---

## 진행 상황

-   `PROGRESS.md` 기록 소급 적용 및 `daily`, `monthly` 파일 생성 완료.
-   **데이터 수집 전략 확정:**
    -   초기 계획이었던 웹 크롤링 방식의 불확실성을 인지하고, **MusicBrainz API**를 주요 데이터 소스로 사용하는 것으로 최종 결정함.
    -   데이터 보강을 위해 **Genius.com API** 등을 보조로 사용하는 **하이브리드 전략**을 채택함.
    -   이에 따라 상단의 작업 계획을 MusicBrainz 연동에 맞게 전면 수정함.
-   `backend/requirements.txt` 파일 생성 및 `musicbrainzngs` 라이브러리 추가 완료.
-   불필요해진 `crawler` 디렉토리 삭제 완료.
-   **데이터베이스 모델 수정 완료**: `models.py`의 `genius_id` 필드를 `mbid` (String)로 성공적으로 변경함.
-   **MusicBrainz API 모듈 생성 완료**: `musicbrainz_api.py`를 생성하고, API 통신을 위한 기본 함수들(아티스트 검색, 릴리즈 정보 조회 등)의 뼈대를 구현함.
-   **서비스 계층 리팩토링 완료**: `services.py`를 MusicBrainz API를 사용하도록 수정하고, `MusicDataService`로 명칭을 변경함. 아티스트 이름으로 모든 릴리즈를 가져와 처리하는 `import_artist_by_name` 서비스 로직의 뼈대를 구현함.
-   **데이터 수집 실행 계획: 연쇄 반응(Chain Reaction) 방식**
    -   **Seed 아티스트**: "kiiikiii"를 데이터 수집의 시작점으로 지정함.
    -   **수집 프로세스**:
        1.  `Person` 모델에 `is_explored` 필드를 추가하여 데이터 탐색 여부를 관리.
        2.  `is_explored=False`인 아티스트("kiiikiii"로 시작)를 탐색.
        3.  `services.py`의 `import_artist_by_name` 함수를 통해 해당 아티스트의 모든 릴리즈와 협업자를 DB에 저장.
        4.  탐색 완료된 아티스트는 `is_explored=True`로 변경.
        5.  새롭게 추가된 협업자들을 대상으로 위 과정을 반복하여, DB 크기가 목표치(약 5GB)에 도달할 때까지 연쇄적으로 데이터를 확장함.
    -   **선행 조건**: 이 계획의 실행을 위해서는 `services.py`의 MusicBrainz 데이터 파싱 로직 구현이 우선되어야 함.
    -   **장기 계획**: 전체 데이터 덤프를 로컬에 구축하는 것은 추후 프로젝트 확장 단계에서 진행하기로 결정함.

---

## 오늘 작업 요약

-   백엔드 아키텍처 리팩토링(서비스 계층 도입) 완료.
-   데이터 수집 전략을 MusicBrainz API를 사용하는 하이브리드 방식으로 최종 확정하고, '연쇄 반응 방식'의 데이터 수집 계획을 수립함.
-   MusicBrainz 연동을 위한 기술적 기반(API 모듈, 서비스 로직 뼈대) 마련 완료.
-   MusicBrainz API를 통한 앨범 정보 조회 과정에서 발생하는 `404 Not Found` 오류에 대한 디버깅이 필요함.
